{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86436a04",
   "metadata": {},
   "source": [
    "# Leveraging remote sensing to explore spatio-temporal dynamics of channel extent and migration in Himalayan lowlands : Response and implications to monsoon flood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a449a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import hydrafloods as hf\n",
    "from rivgraph.classes import river\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from shapely.geometry import LineString\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.ops import unary_union, polygonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ffdd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c328c",
   "metadata": {},
   "source": [
    "## River morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3ce3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = ee.FeatureCollection('users/Nischal_Karki/Bagmati_area').geometry()\n",
    "mesh = ee.FeatureCollection('users/Nischal_Karki/mesh')\n",
    "\n",
    "bn8 = ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B6', 'QA_PIXEL', 'SR_B5', 'SR_B7']\n",
    "bn7 = ['SR_B1', 'SR_B1', 'SR_B2', 'SR_B3', 'SR_B5', 'QA_PIXEL', 'SR_B4', 'SR_B7']\n",
    "bn5 = ['SR_B1', 'SR_B1', 'SR_B2', 'SR_B3', 'SR_B5', 'QA_PIXEL', 'SR_B4', 'SR_B7']\n",
    "bns = ['uBlue', 'Blue', 'Green', 'Red', 'Swir1', 'BQA', 'Nir', 'Swir2']\n",
    "\n",
    "ls5 = ee.ImageCollection(\"LANDSAT/LT05/C02/T1_L2\").select(bn5, bns)\n",
    "ls7 = (ee.ImageCollection(\"LANDSAT/LE07/C02/T1_L2\").select(bn7, bns))\n",
    "ls8 = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\").select(bn8, bns)\n",
    "merged = ls5.merge(ls7).merge(ls8)\n",
    "\n",
    "def Ndvi(image):\n",
    "    return image.normalizedDifference(['Nir', 'Red']).rename('ndvi')\n",
    "\n",
    "def Lswi(image):\n",
    "    return image.normalizedDifference(['Nir', 'Swir1']).rename('lswi')\n",
    "\n",
    "def Mndwi(image):\n",
    "    return image.normalizedDifference(['Green', 'Swir1']).rename('mndwi')\n",
    "\n",
    "def Evi(image):\n",
    "    evi = image.expression('2.5 * (Nir - Red) / (1 + Nir + 6 * Red - 7.5 * Blue)', {\n",
    "    'Nir': image.select(['Nir']),\n",
    "    'Red': image.select(['Red']),\n",
    "    'Blue': image.select(['Blue'])\n",
    "    })\n",
    "    return evi\n",
    "\n",
    "def qa(image):\n",
    "    qa = image.select('BQA')\n",
    "    cloud = qa.bitwiseAnd(1 << 5).And(qa.bitwiseAnd(1 << 7)).Or(qa.bitwiseAnd(1 << 3))\n",
    "    mask2 = image.mask().reduce(ee.Reducer.min())\n",
    "    return image.updateMask(cloud.Not()).updateMask(mask2).multiply(0.0000275).add(-0.2).clip(roi)\n",
    "\n",
    "bnp50 = ['uBlue_p50', 'Blue_p50', 'Green_p50', 'Red_p50', 'Swir1_p50', 'BQA_p50', 'Nir_p50', 'Swir2_p50']\n",
    "\n",
    "def get_mask(imgCol,mndwi_param = -0.35,ndvi_param = 0.15,cleaning_pixels = 100):\n",
    "    p50 = imgCol.reduce(ee.Reducer.percentile([50])).select(bnp50, bns)\n",
    "    \n",
    "    # Apply to each percentile\n",
    "    mndwi_p50 = Mndwi(p50)\n",
    "    ndvi_p50 = Ndvi(p50)\n",
    "    evi_p50 = Evi(p50)\n",
    "    lswi_p50 = Lswi(p50)\n",
    "    \n",
    "    #Water classification from (Zou 2018):\n",
    "    water_p50 = (mndwi_p50.gt(ndvi_p50).Or(mndwi_p50.gt(evi_p50))).And(evi_p50.lt(0.1))\n",
    "    waterMasked_p50 = water_p50.updateMask(water_p50.gt(0))\n",
    "    \n",
    "    #Active river belt classification:\n",
    "    activebelt_p50 = (mndwi_p50.gte(mndwi_param)).And(ndvi_p50.lte(ndvi_param))\n",
    "    activebeltMasked_p50 = activebelt_p50.updateMask(activebelt_p50.gt(0))\n",
    "    active_p50 = (water_p50).Or(activebelt_p50)\n",
    "    \n",
    "    #Clean binary active channel:\n",
    "    smooth_map_p50 = active_p50.focal_mode(radius= 10, kernelType= 'octagon', units= 'pixels', iterations= 1).mask(active_p50.gte(1));\n",
    "    \n",
    "    noise_removal_p50 = active_p50.updateMask(active_p50.connectedPixelCount(cleaning_pixels, False).gte(cleaning_pixels)).unmask(smooth_map_p50);\n",
    "    \n",
    "    #noise_removal_p50_Masked = noise_removal_p50.updateMask(noise_removal_p50.gt(0))\n",
    "    \n",
    "    return noise_removal_p50\n",
    "\n",
    "year=ee.List.sequence(1990,2022)\n",
    "\n",
    "# For downloading annual channel masks\n",
    "def get_annual(year):\n",
    "    imgCol = merged.filterBounds(roi).filter(ee.Filter.calendarRange(year, year, 'year')).map(qa)\n",
    "    wm = get_mask(imgCol)\n",
    "    return wm.set({'year':year})\n",
    "\n",
    "annual_masks = ee.ImageCollection(year.map(get_annual))\n",
    "geemap.ee_export_image_collection_to_drive(annual_masks, scale=10, folder = \"RivMask\", maxPixels=1e10, crs='EPSG:32645',region=roi)\n",
    "\n",
    "# For erosion-accretion areas\n",
    "def calc_area(year):\n",
    "    imgCol1 = merged.filterBounds(roi).filter(ee.Filter.calendarRange(year, year, 'year')).filter(ee.Filter.calendarRange(1, 5, 'month')).map(qa)\n",
    "    imgCol2 = merged.filterBounds(roi).filter(ee.Filter.calendarRange(year, year, 'year')).filter(ee.Filter.calendarRange(6, 12, 'month')).map(qa)\n",
    "    wm1 = get_mask(imgCol1)\n",
    "    wm2 = get_mask(imgCol2)\n",
    "    diff = wm1.subtract(wm2)\n",
    "    E = diff.eq(1)\n",
    "    A = diff.eq(-1)\n",
    "    A_E = A.rename('Accretion').addBands(E.rename('Erosion'))\n",
    "    \n",
    "    def get_stat(img):\n",
    "        area = img.selfMask().multiply(ee.Image.pixelArea()).reduceRegions(collection=mesh,\n",
    "                                                                reducer=ee.Reducer.sum(),\n",
    "                                                                scale=30)\n",
    "        return area.set({'year':year})\n",
    "    \n",
    "    return get_stat(wm)\n",
    "\n",
    "def set_year(fc):\n",
    "    year = ee.FeatureCollection(fc).get('year')\n",
    "    fc_year = ee.FeatureCollection(fc).map(lambda x: x.set({'year':year}))\n",
    "    return fc_year\n",
    "\n",
    "task = ee.batch.Export.table.toDrive(collection=ee.FeatureCollection(ee.FeatureCollection(test.map(set_year)).flatten()), description='total_area',fileFormat='CSV')\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a8df6a",
   "metadata": {},
   "source": [
    "## Centerline migration\n",
    "Download annual channel masks to a folder for centerline delineation. Change `path` to your folder path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee6c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/nischalkarki/Bagmati/RivMask/\"\n",
    "full_path = glob.glob(f'{path}/*.tif')\n",
    "\n",
    "for file in full_path:\n",
    "    try:\n",
    "        mask_path = file\n",
    "        name = file[-8:-4]\n",
    "        results_folder = \"/Users/nischalkarki/Bagmati\"\n",
    "        es = 'NS'\n",
    "        riv = river(name,mask_path,results_folder,exit_sides=es,verbose=True)\n",
    "        riv.skeletonize()\n",
    "        riv.compute_network()\n",
    "        riv.prune_network()\n",
    "        riv.compute_link_width_and_length()\n",
    "        riv.compute_mesh()\n",
    "    \n",
    "    except:\n",
    "        riv.to_geovectors('centerline',ftype='json')\n",
    "\n",
    "mesh = gpd.read_file('/Users/nischalkarki/Bagmati_mesh.shp').to_crs('EPSG:32645')\n",
    "result = gpd.GeoDataFrame()\n",
    "\n",
    "for year in range(1990,2022):\n",
    "    ref_cl = gpd.read_file('/Users/nischalkarki/Bagmati/2022_centerline.json')\n",
    "    ref_cl.crs = 'EPSG:32645'\n",
    "    \n",
    "    cur_cl = gpd.read_file(f'/Users/nischalkarki/Bagmati/{year}_centerline.json')\n",
    "    cur_cl.crs = 'EPSG:32645'\n",
    "    next_cl = gpd.read_file(f'/Users/nischalkarki/Bagmati/{year+1}_centerline.json')\n",
    "    next_cl.crs = 'EPSG:32645'\n",
    "    \n",
    "    ref_cline = ref_cl.overlay(mesh,how=\"intersection\")\n",
    "    ref_cline = ref_cline[['cngmeters','geometry']]\n",
    "    \n",
    "    cur_cline = cur_cl.overlay(mesh,how=\"intersection\")\n",
    "    cur_cline['length']=cur_cline.geometry.apply(lambda geom: geom.length)\n",
    "    cur_cline['year']=year\n",
    "    cur_cline = cur_cline[['cngmeters','length','year']]\n",
    "    \n",
    "    # Extract coordinates from the GeoJSON geometries\n",
    "    line1_coords = list(cur_cl.geometry.iloc[0].coords)\n",
    "    line2_coords = list(next_cl.geometry.iloc[0].coords)\n",
    "    \n",
    "    # Reverse the order of line2_coords for the calculation\n",
    "    line2_coords.reverse()\n",
    "    \n",
    "    # Combine the coordinates and close the loop\n",
    "    combined_coords = line1_coords + line2_coords + [line1_coords[0]]\n",
    "    \n",
    "    # Create a LineString geometry\n",
    "    combined_polyline = LineString(combined_coords)\n",
    "    mls = unary_union(combined_polyline)\n",
    "    \n",
    "    # Polygonize the unioned LineString\n",
    "    polygons = list(polygonize(mls))\n",
    "    \n",
    "    # Create a GeoDataFrame from the polygons\n",
    "    gdf = gpd.GeoDataFrame(geometry=polygons, crs='EPSG:32645')\n",
    "    \n",
    "    area_trav = gdf.dissolve().overlay(mesh,how='intersection').sjoin(mesh, how='left', predicate='within').rename({'cngmeters_left':'cngmeters'},axis='columns')\n",
    "    area_trav['area']=area_trav.geometry.apply(lambda geom: geom.area)\n",
    "    area_trav=area_trav[['cngmeters','area']]\n",
    "    \n",
    "    final = ref_cline.merge(area_trav,on='cngmeters').merge(cur_cline,on='cngmeters')\n",
    "    result = pd.concat([result,final])\n",
    "    \n",
    "result.to_csv('/Users/nischalkarki/Bagmati/migration.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78d4a8c",
   "metadata": {},
   "source": [
    "## Sentinel-1 flood mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eacc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def border_noise(img):\n",
    "    '''\n",
    "    Removes border noise from s1 image;\n",
    "    '''\n",
    "    binary = img.select('VV').lt(-35).rename(\"binary\")\n",
    "    connected = binary.connectedComponents(ee.Kernel.plus(1), 128).select(\"labels\").Not()\n",
    "    mask = binary.where(connected.eq(0),0).Not()\n",
    "    kernel = ee.Kernel.square(5)\n",
    "    mask = mask.reduceNeighborhood(reducer=ee.Reducer.And(), kernel=kernel)\n",
    "    result= img.updateMask(mask)\n",
    "    return result\n",
    "\n",
    "band=\"VV\"\n",
    "\n",
    "s1Collection = ee.ImageCollection('COPERNICUS/S1_GRD') \\ \n",
    ".filterBounds(roi).filterDate('2019-07-13','2019-07-14') \\\n",
    ".filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
    ".filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
    ".filter(ee.Filter.eq('resolution_meters',10)) \\\n",
    ".select(['angle','VV']).map(border_noise)\n",
    "\n",
    "# MERIT Hydro dataset, a hydrologically adjusted DEM from Yamazaki, D. et al. 2019\n",
    "# http://hydro.iis.u-tokyo.ac.jp/~yamadai/MERIT_Hydro/\n",
    "\n",
    "merit = ee.Image(\"MERIT/Hydro/v1_0_1\")\n",
    "dem = merit.select(\"elv\").unmask(0)\n",
    "hand = merit.select(\"hnd\").unmask(0)\n",
    "\n",
    "s1 = hf.Dataset.from_imgcollection(s1Collection)  # ee.ImageCollection to hf.datasets\n",
    "s1_flat = s1.apply_func(hf.slope_correction, elevation=dem, buffer=100) # Terrain flattening\n",
    "s1_filtered = s1_flat.apply_func(hf.refined_lee) # Speckle filtering\n",
    "\n",
    "water = s1_filtered.apply_func(\n",
    "    hf.thresholding.edge_otsu,\n",
    "    initial_threshold=-16,\n",
    "    thresh_no_data=-20,\n",
    "    edge_buffer=300\n",
    ")\n",
    "\n",
    "# Extract permanent water from Dynamic World dataset - near real time global landcover from sentinel-2\n",
    "dwCol = ee.ImageCollection('GOOGLE/DYNAMICWORLD/V1').filterBounds(region).filterDate('2019-01-01', '2019-12-31')\n",
    "dwImage = dwCol.select('label').mode()\n",
    "dw_mask = dwImage.eq(0)\n",
    "\n",
    "def post_process(img):\n",
    "    final = (\n",
    "    hf.close_binary(\n",
    "        hf.open_binary(img, window=1.5) # apply opening filter\n",
    "        .updateMask(img.mask()), # force mask to be consistent with sar imagery\n",
    "        window=1.5\n",
    "    ) # apply closing filter\n",
    "    .updateMask(img.mask()) # force mask to be consistent with sar imagery\n",
    "    .updateMask(hand.lt(15)) # only pixels that were originally classified as water AND < 15m from HAND (Height Above Nearest Drainage)\n",
    "    .updateMask(dw_mask.Not()) # remove permanent water\n",
    "    )\n",
    "    connected = final.selfMask().connectedPixelCount()\n",
    "    final_img = final.selfMask().updateMask(connected.gte(10))\n",
    "    return final_img.selfMask()\n",
    "\n",
    "water_final = water.collection.map(post_process)\n",
    "\n",
    "task = ee.batch.Export.image.toDrive(image=water_final, region = roi, crs=\"EPSG:32645\",scale=10, maxPixels=1e10,description= \"Bagmati_flood\")\n",
    "task.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
